# Quantized-Phi3
This is the repository that demonstrates the quantization of phi3-4k-instruct model made by Microsoft using the GGUF format leveraging llama.cpp. Feel free to use this model as it can have blazing fast inference locally and the best part being, it is less compute hunger.
